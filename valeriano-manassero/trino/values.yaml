image:
  repository: trinodb/trino
  tag: 433
  pullPolicy: IfNotPresent

fullnameOverride: trino

imagePullSecrets: []
# For example:
# imagePullSecrets:
#   - name: registry-credentials

ingress:
  enabled: false
  ingressClassName:
  annotations: {}
    # kubernetes.io/ingress.class: nginx
  host: ""
  tls:
    secretName: ""

clusterDomain: cluster.local

config:
  general:
    node:
      environment: production
      dataDir: /data/trino
      pluginDir: /usr/lib/trino/plugin
    log:
      trino:
        level: INFO
    path: /etc/trino
    http:
      port: 8080
    processForwarded: false
    # -- Trino supports multiple authentication types: PASSWORD, CERTIFICATE, OAUTH2, JWT, KERBEROS
    # For more info: https://trino.io/docs/current/security/authentication-types.html
    authenticationType: ""
    catalogsMountType: "secret"
    httpsServer:
      enabled: false
      port: 8443
      keystore:
        path: "/usr/local/certs/clustercoord.pem"
        # JKS keystores always require a password, while PEM format certificates can optionally require a password
        key: ""
    internalCommunicationSharedSecret: some-secret
    query:
      maxMemory: "3GB"
      maxTotalMemory: "6GB"
    prestoCompatibleHeader: false
    env: []
    envFrom: []

  coordinator:
    replicas: 1
    env: []
    envFrom: []
    nodeSelector: {}
    tolerations: []
    affinity: {}
    podLabels: {}
    podAnnotations: {}
    resources: {}
    # limits:
    #  cpu: 100m
    #  memory: 128Mi
    # requests:
    #  cpu: 100m
    #  memory: 128Mi
    initContainers: []
    #   - name: init-coordinator
    #     image: busybox:1.28
    #     imagePullPolicy: IfNotPresent
    #     command: ['sh', '-c', "until nslookup myservice.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done"]
    jvm:
      maxRAMPercentage: 80.0
      gcMethod:
        type: "UseG1GC"
        g1:
          heapRegionSize: "32M"
    jvmExtraConfig: ""
    extraConfig: ""
    query:
      maxMemoryPerNode: "1GB"

  worker:
    # -- Replica count when autoscaler is disabled. If autoscaler is enabled, it sets minimum number of replicas.
    replicas: 2
    env: []
    envFrom: []
    nodeSelector: {}
    tolerations: []
    affinity: {}
    podLabels: {}
    podAnnotations: {}
    resources: {}
    # limits:
    #  cpu: 100m
    #  memory: 128Mi
    # requests:
    #  cpu: 100m
    #  memory: 128Mi
    initContainers: []
    # worker:
    #   - name: init-worker
    #     image: busybox:1.28
    #     command: ['sh', '-c', 'echo The worker is running! && sleep 3600']
    jvm:
      maxRAMPercentage: 80.0
      gcMethod:
        type: "UseG1GC"
        g1:
          heapRegionSize: "32M"
    jvmExtraConfig: ""
    extraConfig: ""
    query:
      maxMemoryPerNode: "1GB"
    autoscaler:
      enabled: false
      maxReplicas: 5
      targetCPUUtilizationPercentage: 50
      stabilizationWindowSeconds: 300
    # allows for using lifecycle hooks to set node as marked for eviction
    lifecycle: {}
      # sample config for no auth cluster
      # preStop:
      #   exec:
      #     command: ["sh", "-c", "curl -v -X PUT -d '\"SHUTTING_DOWN\"' -H \"Content-type: application/json\" -H \"X-Trino-User: admin\" http://localhost:8080/v1/info/state"]
    extraVolumeMounts: {}
      # sample config for temp storage volume mount
      # localtemp:
      #   mountpath: /tmp/localtemp
      #   readOnly: false
    extraVolumes: {}
      # sample config for temp storage volume
      # localtemp:
      #   hostPath:
      #     path: /mnt


eventListenerProperties: {}

# -- Password authenticator configuration, an item per conf line. Requiere `config.general.authenticationType` set to `PASSWORD`.
# For file : you don't need to use this propertie if you set `config.general.authenticationType` to `PASSWORD` and use `config.auth` to fill `auth/password.db`.
# For LDAP : https://trino.io/docs/current/security/ldap.html.
# For SalesForce : https://trino.io/docs/current/security/salesforce.html
passwordAuthenticatorProperties: {}

auth: {}
  # Set username and password
  # https://trino.io/docs/current/security/password-file.html#file-format
  # passwordAuth: "username:encrypted-password-with-htpasswd"

accessControl: {}
  # # Supported types: pvc or configmap
  # type: pvc
  # refreshPeriod: 1s
  # # Rules file is mounted to /etc/trino/access-control
  # configFile: "/access-control/rules.json"
  # # If you use pvc as the type, you have to specify the pvcName field:
  # pvcName:
  # # If you use pvc as the type, you can specify the name of the volume with the pvcVolumeName:
  # pvcVolumeName:
  # # If you use configmap as the type, you have to specify the rules field:
  # rules:
  #   rules.json: |-
  #     {
  #       "catalogs": [
  #         {
  #           "user": "admin",
  #           "catalog": "(mysql|system)",
  #           "allow": "all"
  #         },
  #         {
  #           "group": "finance|human_resources",
  #           "catalog": "postgres",
  #           "allow": true
  #         },
  #         {
  #           "catalog": "hive",
  #           "allow": "all"
  #         },
  #         {
  #           "user": "alice",
  #           "catalog": "postgresql",
  #           "allow": "read-only"
  #         },
  #         {
  #           "catalog": "system",
  #           "allow": "none"
  #         }
  #       ],
  #       "schemas": [
  #         {
  #           "user": "admin",
  #           "schema": ".*",
  #           "owner": true
  #         },
  #         {
  #           "user": "guest",
  #           "owner": false
  #         },
  #         {
  #           "catalog": "default",
  #           "schema": "default",
  #           "owner": true
  #         }
  #       ]
  #     }

resourceGroups: {}
  # # Supported types: pvc or configmap
  # type: pvc
  # # Rules file is mounted to /etc/trino/resource-groups
  # configFile: "/resource-groups/resource-groups.json"
  # # If you use pvc as the type, you have to specify the pvcName field:
  # pvcName:
  # # If you use pvc as the type, you can specify the name of the volume with the pvcVolumeName:
  # pvcVolumeName:
  # # If you use configmap as the type, you have to specify the rules field:
  # rules:
  #   resource-groups.json: |-
  #     {
  #       "rootGroups": [
  #         {
  #           "name": "global",
  #           "softMemoryLimit": "80%",
  #           "hardConcurrencyLimit": 100,
  #           "maxQueued": 1000,
  #           "schedulingPolicy": "weighted",
  #           "jmxExport": true,
  #           "subGroups": [
  #             {
  #               "name": "data_definition",
  #               "softMemoryLimit": "10%",
  #               "hardConcurrencyLimit": 5,
  #               "maxQueued": 100,
  #               "schedulingWeight": 1
  #             },
  #             {
  #               "name": "adhoc",
  #               "softMemoryLimit": "10%",
  #               "hardConcurrencyLimit": 50,
  #               "maxQueued": 1,
  #               "schedulingWeight": 10,
  #               "subGroups": [
  #                 {
  #                   "name": "other",
  #                   "softMemoryLimit": "10%",
  #                   "hardConcurrencyLimit": 2,
  #                   "maxQueued": 1,
  #                   "schedulingWeight": 10,
  #                   "schedulingPolicy": "weighted_fair",
  #                   "subGroups": [
  #                     {
  #                       "name": "${USER}",
  #                       "softMemoryLimit": "10%",
  #                       "hardConcurrencyLimit": 1,
  #                       "maxQueued": 100
  #                     }
  #                   ]
  #                 },
  #                 {
  #                   "name": "bi-${toolname}",
  #                   "softMemoryLimit": "10%",
  #                   "hardConcurrencyLimit": 10,
  #                   "maxQueued": 100,
  #                   "schedulingWeight": 10,
  #                   "schedulingPolicy": "weighted_fair",
  #                   "subGroups": [
  #                     {
  #                       "name": "${USER}",
  #                       "softMemoryLimit": "10%",
  #                       "hardConcurrencyLimit": 3,
  #                       "maxQueued": 10
  #                     }
  #                   ]
  #                 }
  #               ]
  #             },
  #             {
  #               "name": "pipeline",
  #               "softMemoryLimit": "80%",
  #               "hardConcurrencyLimit": 45,
  #               "maxQueued": 100,
  #               "schedulingWeight": 1,
  #               "jmxExport": true,
  #               "subGroups": [
  #                 {
  #                   "name": "pipeline_${USER}",
  #                   "softMemoryLimit": "50%",
  #                   "hardConcurrencyLimit": 5,
  #                   "maxQueued": 100
  #                 }
  #               ]
  #             }
  #           ]
  #         },
  #         {
  #           "name": "admin",
  #           "softMemoryLimit": "100%",
  #           "hardConcurrencyLimit": 50,
  #           "maxQueued": 100,
  #           "schedulingPolicy": "query_priority",
  #           "jmxExport": true
  #         }
  #       ],
  #       "selectors": [
  #         {
  #           "user": "bob",
  #           "group": "admin"
  #         },
  #         {
  #           "userGroup": "admin",
  #           "group": "admin"
  #         },
  #         {
  #           "source": ".*pipeline.*",
  #           "queryType": "DATA_DEFINITION",
  #           "group": "global.data_definition"
  #         },
  #         {
  #           "source": ".*pipeline.*",
  #           "group": "global.pipeline.pipeline_${USER}"
  #         },
  #         {
  #           "source": "jdbc#(?<toolname>.*)",
  #           "clientTags": ["hipri"],
  #           "group": "global.adhoc.bi-${toolname}.${USER}"
  #         },
  #         {
  #           "group": "global.adhoc.other.${USER}"
  #         }
  #       ],
  #       "cpuQuotaPeriod": "1h"
  #     }

# If you want to provide your own secrets resource, you can use this field:
# connectorsSecret:
# authenticationSecret:
# faultToleranceSecret:

groupProvider: {}
  # # Supported types: pvc or configmap
  # name: file
  # type: pvc
  # refreshPeriod: 5s
  # # Rules file is mounted to /etc/trino/group-provider
  # configFile: "/group-provider/groups.txt"
  # # If you use pvc as the type, you have to specify the pvcName field:
  # pvcName:
  # # If you use pvc as the type, you can specify the name of the volume with the pvcVolumeName:
  # pvcVolumeName:
  # # If you use configmap as the type, you have to specify the groups field:
  # groups:
  #   groups.txt: |-
  #    group_name:user_1,user_2,user_3
  # customProperties: |-
  #   custom-property1=custom-value1
  #   custom-property2=custom-value2

faultTolerance:
  enabled: false
  configAsSecret: true
  # properties: |-
  #   exchange-manager.name=filesystem
  #   exchange.base-directories=s3://<bucket-name>
  #   exchange.s3.region=us-east-1
  #   exchange.s3.aws-access-key=<access-key>
  #   exchange.s3.aws-secret-key=<secret-key>

connectors: {}
  # Connectors configuration usually contains sensitive data (like passwords, usernames, ...)
  # so data is stored in a secret
  # mysql.properties: |-
  #   connector.name=mysql
  #   connection-url=jdbc:mysql://mysqlserver:3306
  #   connection-user=mysqluser
  #   connection-password=mysqlpassword
  # elk.properties: |-
  #   connector.name=elasticsearch
  #   elasticsearch.host=elasticsearchserver
  #   elasticsearch.port=9200
  #   elasticsearch.default-schema-name=default
  #   elasticsearch.security=PASSWORD
  #   elasticsearch.auth.user=elastiuser
  #   elasticsearch.auth.password=elasticpassword
  #   elasticsearch.tls.enabled=true

catalogs: {}
  # Catalogs that will be mounted in {{ .Values.config.general.path }}/catalog
  # Requires config.general.catalogsMountType = "configmap"
  # tpch.properties: |
  #   connector.name=tpch
  #   tpch.splits-per-node=4
  # tpcds.properties: |
  #   connector.name=tpcds
  #   tpcds.splits-per-node=4

schemas: {}
  # Custom schemas that will be mounted in /etc/trino/schemas
  # testschema.json: |-
  #   {
  #     "tableName": "testtable",
  #     "schemaName": "testschema",
  #     "topicName": "testtopic",
  #     "key": {
  #         "dataFormat": "json",
  #         "fields": [
  #             {
  #                 "name": "_key",
  #                 "dataFormat": "VARCHAR",
  #                 "type": "VARCHAR",
  #                 "hidden": "false"
  #             }
  #         ]
  #     },
  #     "message": {
  #         "dataFormat": "json",
  #         "fields": [
  #             {
  #                 "name": "id",
  #                 "mapping": "id",
  #                 "type": "BIGINT"
  #             },
  #             {
  #                 "name": "test_field",
  #                 "mapping": "test_field",
  #                 "type": "VARCHAR"
  #             }
  #         ]
  #     }
  #   }

service:
  type: ClusterIP

secretMounts: []
  # - name: ssl-cert
  #   secretName: ssl-cert
  #   path: /usr/local/certs/
  # - name: ssh-key
  #   secretName: ssh-key
  #   path: /home/trino/.ssh/id_rsa.pub
  #   subPath: id_rsa.pub

configMapMounts: []
  # - name: ssh-config
  #   configMapName: ssh-config
  #   path: /home/trino/.ssh/config
  #   subPath: config

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# sets extra service annotations for the trino server service
serviceAnnotations: {}

# -- SecurityContext configuration for pods
podSecurityContext:
  runAsUser: 1000
  runAsGroup: 1000
  fsGroup: 1000
  runAsNonRoot: true
  seccompProfile:
    type: RuntimeDefault

# -- SecurityContext configuration for containers
containerSecurityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
      - ALL

initKeystore:
  image:
    repository: bitnami/java
    tag: 17
    pullPolicy: IfNotPresent

tls:
  # Set internode encryption
  internodeEncryption: false
  # Generate automatically self-signed TLS certificates. Currently only supports PEM certificates
  autoGenerated: false
  # Existing secret that contains the keystore
  existingKeystoreSecret: ""
  # Existing secret that contains the cert and key for the keystore
  tlsEncryptionSecretName: ""
  # Existing secret that contains the password to the keystore
  keystorePasswordSecret: ""
  resources: {}
    # limits:
    #  cpu: 100m
    #  memory: 128Mi
    # requests:
    #  cpu: 100m
    #  memory: 128Mi

jmxExporter:
  coordinator:
    enabled: false
  worker:
    enabled: false
  port: 9000
  path: /prometheus
  jarfile: jmx_prometheus_javaagent-0.17.2.jar
  downloadLink: https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.17.2/jmx_prometheus_javaagent-0.17.2.jar
  image:
    repository: curlimages/curl
    tag: 7.87.0
    pullPolicy: IfNotPresent
  serviceMonitor:
    enabled: true
    port: "jmx-exporter"
    additionalLabels: {}
    interval: 1m
    scrapeTimeout: 10s
    path: /metrics
    # Additional relabeling configs to the ones that Prometheus Operator
    # creates by default.
    # relabelings:
    #   - sourceLabels: [__meta_kubernetes_endpoints_label_app_kubernetes_io_version]
    #     targetLabel: version
